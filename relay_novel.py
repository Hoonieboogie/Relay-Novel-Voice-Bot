""" 
- Streamlitì€ ì½”ë“œê°€ ìœ„â†’ì•„ë˜ í•œ ë²ˆ ì‹¤í–‰ í›„ ì´ë²¤íŠ¸ ë•Œë§ˆë‹¤ rerun ë˜ëŠ” êµ¬ì¡°ë¼ while True ê°™ì€ ë¬´í•œ ë£¨í”„ê°€ UI ê°±ì‹ ì„ ë§‰ì•„ë²„ë ¤ìš”.
- recognizer.listen() ê°™ì€ ë¸”ë¡œí‚¹ í•¨ìˆ˜ëŠ” ì‹¤í–‰ ì¤‘ì— Streamlit í™”ë©´ì´ ë©ˆì¶° ë³´ì´ê²Œ í•´ìš”.
- ë”°ë¼ì„œ í„°ë¯¸ë„ì²˜ëŸ¼ ì‹¤ì‹œê°„ ëŒ€ê¸°/ì¶œë ¥ì„ í•˜ëŠ” êµ¬ì¡°ë¥¼ Streamlitì—ì„œëŠ” ê·¸ëŒ€ë¡œ êµ¬í˜„í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.
"""

# ======================================================================
# ëŒ€ì•ˆ: ë…¹ìŒ ë²„íŠ¼ ì´ìš©í•˜ê¸°
import speech_recognition as sr
from openai import OpenAI
from dotenv import load_dotenv
import os, time

# 1) API í‚¤ ë¡œë“œ
load_dotenv()
client = OpenAI()

# 2) SpeechRecognition (ë…¹ìŒìš©, STTëŠ” Whisper API ì‚¬ìš©)
recognizer = sr.Recognizer()

# 3) GPT ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
system_prompt = """
ë„ˆëŠ” ë‚˜ë‘ ë¦´ë ˆì´ ì†Œì„¤ì„ ì“¸ê±°ì•¼. ì„œë¡œ ë²ˆê°ˆì•„ í•œ ë¬¸ì¥ì”© ì´ì–´ì„œ ë§í•˜ì.
ì¥ë¥´ëŠ” ë‚´ê°€ ë§í•´ì¤„í…Œë‹ˆê¹Œ ë¨¼ì € ì„ì˜ë¡œ ì •í•˜ì§€ë§ˆ.
ë„ˆëŠ” ë…¸ë²¨ë¬¸í•™ìƒì„ íƒˆ ë§Œí¼ ê·¸ ë¶„ì•¼ì—ì„œ ìµœê³  ê¶Œìœ„ìì•¼.
ëª…ì‹¬í•´. ë§¥ë½ì— ë§ê²Œ ì†Œì„¤ì„ ì§€ì–´ë‚´.
ê·¸ë¦¬ê³  ë‚˜ë‘ ë§í•  ë•ŒëŠ” ë°˜ë§ í•˜ê³ , ì†Œì„¤ ì“¸ ë•ŒëŠ” ë§¥ë½ì— ë§ê²Œ í•´.
"""
messages = [{"role": "system", "content": system_prompt}]

def trim_messages(msgs, max_turns=20):
    sys = msgs[:1]
    rest = msgs[1:]
    return sys + rest[-(max_turns*2):]

with sr.Microphone() as source:
    # ğŸ™ ì£¼ë³€ ì†ŒìŒ ë³´ì •
    print("ğŸ™ ì£¼ë³€ ì†ŒìŒ ë³´ì • ì¤‘...")
    recognizer.adjust_for_ambient_noise(source, duration=0.5)
    print("âœ… ì¤€ë¹„ ì™„ë£Œ! 'ì¢…ë£Œ'ë¼ê³  ë§í•˜ë©´ ëë‚©ë‹ˆë‹¤.")

    while True:
        print("\nğŸ¤ ë§ì”€í•˜ì„¸ìš”...")
        audio = recognizer.listen(source, phrase_time_limit=15)  # ìµœëŒ€ 15ì´ˆê¹Œì§€ë§Œ ë“£ê¸°

        try:
            # 1) ìŒì„±ì„ wav íŒŒì¼ë¡œ ì €ì¥
            with open("user_input.wav", "wb") as f:
                f.write(audio.get_wav_data())

            # 2) Whisper APIë¡œ STT
            with open("user_input.wav", "rb") as f:
                transcription = client.audio.transcriptions.create(
                    model="whisper-1",
                    file=f,
                    language="ko"
                )
            txt = transcription.text.strip()
            print("ë‚˜:", txt)

            if txt in {"ì¢…ë£Œ", "ë", "ê·¸ë§Œ"}:
                print("ğŸ‘‹ ëŒ€í™” ì¢…ë£Œ")
                break

            # 3) GPT ì‘ë‹µ
            messages.append({"role": "user", "content": txt})
            messages = trim_messages(messages)
            gpt_reply = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                temperature=0.7,
                max_tokens=256
            ).choices[0].message.content
            messages.append({"role": "assistant", "content": gpt_reply})

            # 4) GPT ë‹µë³€ì„ TTS(mp3)ë¡œ ë³€í™˜
            with client.audio.speech.with_streaming_response.create(
                model="tts-1",
                voice="nova",
                input=gpt_reply
            ) as response:
                response.stream_to_file("gpt_reply.mp3")

            # 5) ì¬ìƒ (macOS)
            print("ë´‡:", gpt_reply)
            os.system("afplay gpt_reply.mp3")
            # Windows â†’ os.system("start gpt_reply.mp3")

            # ì†Œë¦¬ ëë‚˜ê¸° ì „ì— ë‹¤ìŒ listen ë“¤ì–´ê°€ë©´ í”¼ë“œë°± ë£¨í”„ ìƒê¸¸ ìˆ˜ ìˆìŒ â†’ ì§§ê²Œ ëŒ€ê¸°
            time.sleep(0.1)

        except Exception as e:
            print("âš ï¸ ì˜¤ë¥˜:", e)