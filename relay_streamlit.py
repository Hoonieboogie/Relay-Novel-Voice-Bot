import streamlit as st
import speech_recognition as sr
from openai import OpenAI
from dotenv import load_dotenv
import os, io
import base64

# ===== ì´ˆê¸°í™” =====
load_dotenv()
client = OpenAI()
recognizer = sr.Recognizer()

SYSTEM_PROMPT = """
ë„ˆëŠ” ë‚˜ë‘ ê³ í€„ë¦¬í‹° ë¦´ë ˆì´ ì†Œì„¤ì„ ì“¸ê±°ì•¼. ê·¸ë¦¬ê³  ë„ˆëŠ” ë…¸ë²¨ë¬¸í•™ìƒì„ íƒˆ ë§Œí¼ ê·¸ ë¶„ì•¼ì—ì„œ ìµœê³  ê¶Œìœ„ìë‹ˆê¹Œ ê·¸ì— ë§ëŠ” í•„ë ¥ì„ ë³´ì—¬ì¤˜.
ë‹¤ìŒì˜ ì§€ì‹œ ì‚¬í•­ì„ ì² ì €í•˜ê²Œ ìˆ™ì§€í•˜ê³  ë”°ë¼ì•¼í•´.

###ì§€ì‹œ ì‚¬í•­###
- ë„ˆë‘ ë‚˜ë‘ ì„œë¡œ ë²ˆê°ˆì•„ í•œ ë¬¸ì¥ì”© ì´ì–´ì„œ ë§í•˜ì.
- ì¥ë¥´ëŠ” ë‚´ê°€ ë§í•´ì¤„í…Œë‹ˆê¹Œ ë¨¼ì € ì„ì˜ë¡œ ì •í•˜ì§€ë§ˆ. 
- ì‹œì‘ì€ í•­ìƒ ë‚˜ì•¼. ê·¸ëŸ¬ë‹ˆê¹Œ ë¨¼ì € ì´ì•¼ê¸°ë¥¼ ì‹œì‘í•˜ì§€ ë§ê³ , ë‚˜í•œí…Œ ì‹œì‘í•´ë‹¬ë¼ê³  í•´.
- ë˜ ë‚´ê°€ ì¤‘ê°„ì— ì¥ë¥´ë¥¼ ë°”ê¾¸ìê³  í•˜ë©´, ë°”ë¡œ ê·¸ ì¥ë¥´ì— ë§ì¶°ì„œ ì†Œì„¤ì„ ì´ì–´ê°€.
- ë‚˜ë‘ ë§í•  ë•ŒëŠ” ë°˜ë§ í•˜ê³ , ì†Œì„¤ ì“¸ ë•ŒëŠ” ë§¥ë½ì— ë§ê²Œ í•´.
"""

# ===== ì„¸ì…˜ ìƒíƒœ =====
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "system", "content": SYSTEM_PROMPT}]
if "history" not in st.session_state:
    st.session_state.history = []   # (speaker, text) íŠœí”Œ
if "is_listening" not in st.session_state:
    st.session_state.is_listening = False   # ë…¹ìŒ ì¤‘ ì—¬ë¶€ í‘œì‹œ

# í† í° í•œë„ ì´ˆê³¼ ë°©ì§€
def trim_messages(msgs, max_turns=20):
    sys = msgs[:1]
    rest = msgs[1:]
    return sys + rest[-(max_turns*2):]  # ìµœê·¼ 20í„´ ìœ ì§€

# ===== UI =====
# ===== ë¡œì»¬ ì´ë¯¸ì§€ base64 ë³€í™˜ =====
def get_base64_of_bin_file(bin_file):
    with open(bin_file, "rb") as f:
        data = f.read()
    return base64.b64encode(data).decode()

img_base64 = get_base64_of_bin_file("lips.png")

# ===== CSSë¡œ ë°°ê²½ ì´ë¯¸ì§€ ë„£ê¸° (íˆ¬ëª… ì˜¤ë²„ë ˆì´ í¬í•¨) =====
st.markdown(
    f"""
    <style>
    .stApp {{
        background-image: url("data:image/png;base64,{img_base64}");
        background-repeat: repeat;         /* ë°”ë‘‘íŒì‹ ë°˜ë³µ */
        background-size: 150px 150px;      /* ê° ì´ë¯¸ì§€ í¬ê¸° */
    }}
    .stApp::before {{
        content: "";
        position: absolute;
        top: 0;
        left: 0;
        right: 0;
        bottom: 0;
        background: rgba(0, 0, 0, 0.5); /* ê²€ì€ìƒ‰ ë°˜íˆ¬ëª… ì˜¤ë²„ë ˆì´ */
        z-index: 0;
    }}
    .stApp > div {{
        position: relative;
        z-index: 1;
    }}
    </style>
    """,
    unsafe_allow_html=True
)


st.title("Relay...ì†Œì„¤ ğŸ«¦")

# ===== ë§í•˜ê¸° ë²„íŠ¼ =====
if st.button("ğŸ¤ ë§í•˜ê¸°"):
    with sr.Microphone() as source:
        st.markdown("---")
        
        # ì•ˆë‚´ ë¬¸êµ¬ë¥¼ ë„£ì„ ìë¦¬ í™•ë³´
        msg_box = st.empty()
        msg_box.info("ë§ì”€í•˜ì„¸ìš”...")

        recognizer.adjust_for_ambient_noise(source, duration=0.6)
        recognizer.pause_threshold = 1.2
        audio = recognizer.listen(source, phrase_time_limit=15)

        # ë…¹ìŒì´ ëë‚˜ëŠ” ì¦‰ì‹œ ì•ˆë‚´ ë¬¸êµ¬ ì œê±°
        msg_box.empty()
    
    try:
        # 1) Whisper STT
        with open("user_input.wav", "wb") as f:
            f.write(audio.get_wav_data())
        with open("user_input.wav", "rb") as f:
            transcription = client.audio.transcriptions.create(
                model="whisper-1",
                file=f,
                language="ko"
            )
        txt = transcription.text.strip()

        # --- STT ê²°ê³¼ ë¨¼ì € ì¶œë ¥ ---
        st.session_state.history.append(("ë‚˜", txt))
        st.markdown(f"<p style='text-align:center; color:white;'><b>ë‚˜:</b> {txt}</p>", unsafe_allow_html=True)

        if txt in {"ì¢…ë£Œ", "ë", "ê·¸ë§Œ"}:
            st.warning("ğŸ‘‹ ëŒ€í™” ì¢…ë£Œ")
        else:
            # 2) GPT ì‘ë‹µ
            st.session_state.messages.append({"role": "user", "content": txt})
            st.session_state.messages = trim_messages(st.session_state.messages)

            gpt_reply = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=st.session_state.messages,
                temperature=0.7,
                max_tokens=256
            ).choices[0].message.content

            # --- GPT ë‹µë³€ ì¦‰ì‹œ ì¶œë ¥ ---
            st.session_state.history.append(("ë´‡", gpt_reply))
            st.markdown(f"<p style='text-align:center; color:orange;'><b>ë´‡:</b> {gpt_reply}</p>", unsafe_allow_html=True)

            # 3) TTS ë³€í™˜ + ì¬ìƒ
            with client.audio.speech.with_streaming_response.create(
                model="tts-1",
                voice="nova",
                input=gpt_reply
            ) as response:
                response.stream_to_file("gpt_reply.mp3")

            #os.system("afplay gpt_reply.mp3")   # macOS
            # Windowì—ì„œëŠ” í”Œë ˆì´ì–´ê°€ ì¬ìƒë˜ê¸° ë•Œë¬¸ì— ë°‘ì— ë°©ì‹ìœ¼ë¡œ ì „í™˜
            audio_file = open("gpt_reply.mp3", "rb")
            audio_bytes = audio_file.read()
            st.audio(audio_bytes, format="audio/mp3")
            
            st.session_state.is_listening = False # ë…¹ìŒ & ì²˜ë¦¬ ëë‚˜ë©´ ìƒíƒœ ì´ˆê¸°í™”

    except Exception as e:
        st.error(f"âš ï¸ ì˜¤ë¥˜: {e}")


# ===== í•­ìƒ íˆìŠ¤í† ë¦¬ ì „ì²´ ì¶œë ¥ =====
st.markdown("---")
for speaker, text in st.session_state.history:
    align = "left" if speaker == "ë‚˜" else "right"
    color = "white" if speaker == "ë‚˜" else "orange"
    st.markdown(
        f"<p style='text-align:{align}; color:{color};'><b>{speaker}:</b> {text}</p>",
        unsafe_allow_html=True,
    )